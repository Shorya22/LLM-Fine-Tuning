{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U transformers accelerate datasets bitsandbytes peft trl datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:58:58.911355Z","iopub.execute_input":"2024-05-19T04:58:58.912168Z","iopub.status.idle":"2024-05-19T04:59:31.255979Z","shell.execute_reply.started":"2024-05-19T04:58:58.912135Z","shell.execute_reply":"2024-05-19T04:59:31.254731Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer,AutoModelForCausalLM,TrainingArguments,BitsAndBytesConfig,pipeline,Trainer,DataCollatorForLanguageModeling\nimport torch\nfrom peft import LoraConfig,PeftModel,prepare_model_for_kbit_training,get_peft_model,TaskType\nfrom trl import SFTTrainer\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:59:31.257840Z","iopub.execute_input":"2024-05-19T04:59:31.258152Z","iopub.status.idle":"2024-05-19T04:59:49.389349Z","shell.execute_reply.started":"2024-05-19T04:59:31.258126Z","shell.execute_reply":"2024-05-19T04:59:49.388430Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-19 04:59:38.551197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-19 04:59:38.551296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-19 04:59:38.655626: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"b-mc2/sql-create-context\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:59:49.390742Z","iopub.execute_input":"2024-05-19T04:59:49.391294Z","iopub.status.idle":"2024-05-19T04:59:57.495082Z","shell.execute_reply.started":"2024-05-19T04:59:49.391269Z","shell.execute_reply":"2024-05-19T04:59:57.494339Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/4.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15693e81cf4b49eb8237c5f7a07f2f05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d485af1724b14bec8449a2658cba1cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/78577 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d12252784c89495eb9e95a65212bf444"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:59:57.497140Z","iopub.execute_input":"2024-05-19T04:59:57.497446Z","iopub.status.idle":"2024-05-19T04:59:57.505483Z","shell.execute_reply.started":"2024-05-19T04:59:57.497402Z","shell.execute_reply":"2024-05-19T04:59:57.504476Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['answer', 'question', 'context'],\n        num_rows: 78577\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"base_model_id= \"NousResearch/Hermes-2-Pro-Mistral-7B\"","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:59:57.506659Z","iopub.execute_input":"2024-05-19T04:59:57.506938Z","iopub.status.idle":"2024-05-19T04:59:57.538805Z","shell.execute_reply.started":"2024-05-19T04:59:57.506915Z","shell.execute_reply":"2024-05-19T04:59:57.538005Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer= AutoTokenizer.from_pretrained(base_model_id,use_fast=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side='right'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:59:57.539909Z","iopub.execute_input":"2024-05-19T04:59:57.540246Z","iopub.status.idle":"2024-05-19T05:00:00.344567Z","shell.execute_reply.started":"2024-05-19T04:59:57.540207Z","shell.execute_reply":"2024-05-19T05:00:00.343735Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/6.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263d22791c7349a4a9744cbbbcfa7ef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"494f080632ec4ea79ffe02d9a953d674"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/643 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c594edd2b1e4e26a5ec85b44eb7fb5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1778d9fa4bb74b868b91bff59afc65ce"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_data(sample):\n    start_prompt= \"Write SQL query according to given question or instruction.\\n\\n\"\n    end_prompt= \"\\n\\nResponse:\"\n    prompt= [start_prompt+question+end_prompt for question in sample['question']]\n    sample['input_ids']= tokenizer(prompt,padding='max_length',truncation=True,return_tensors='pt',max_length=512,).input_ids\n    sample['labels']= tokenizer(sample['answer'],padding='max_length',truncation=True,return_tensors='pt',max_length=512).input_ids\n    \n    return sample","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:00:00.345568Z","iopub.execute_input":"2024-05-19T05:00:00.345877Z","iopub.status.idle":"2024-05-19T05:00:00.352223Z","shell.execute_reply.started":"2024-05-19T05:00:00.345851Z","shell.execute_reply":"2024-05-19T05:00:00.351386Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset= dataset.map(tokenize_data,batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:00:00.353381Z","iopub.execute_input":"2024-05-19T05:00:00.353725Z","iopub.status.idle":"2024-05-19T05:01:11.391780Z","shell.execute_reply.started":"2024-05-19T05:00:00.353695Z","shell.execute_reply":"2024-05-19T05:01:11.390859Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/78577 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243a72f556ec422bbc53f9a0064799f5"}},"metadata":{}}]},{"cell_type":"code","source":"dataset=dataset.remove_columns(['answer', 'question', 'context'])","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:01:11.392840Z","iopub.execute_input":"2024-05-19T05:01:11.393139Z","iopub.status.idle":"2024-05-19T05:01:11.399743Z","shell.execute_reply.started":"2024-05-19T05:01:11.393115Z","shell.execute_reply":"2024-05-19T05:01:11.398922Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset=dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:01:11.402882Z","iopub.execute_input":"2024-05-19T05:01:11.403168Z","iopub.status.idle":"2024-05-19T05:01:11.533236Z","shell.execute_reply.started":"2024-05-19T05:01:11.403146Z","shell.execute_reply":"2024-05-19T05:01:11.532375Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset= dataset.select(range(1000))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:01:11.534321Z","iopub.execute_input":"2024-05-19T05:01:11.534627Z","iopub.status.idle":"2024-05-19T05:01:11.544508Z","shell.execute_reply.started":"2024-05-19T05:01:11.534603Z","shell.execute_reply":"2024-05-19T05:01:11.543689Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Quantization Config \nbnb_config= BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True)\n\n# LoRA COnfig\npeft_config= LoraConfig(lora_alpha=15,\n                        lora_dropout=0.1,\n                        target_modules=[\n                                    'q_proj',\n                                    'k_proj',\n                                    'v_proj',\n                                    'dense'],\n                        bias=\"none\",\n                        task_type=TaskType.CAUSAL_LM)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:01:11.545732Z","iopub.execute_input":"2024-05-19T05:01:11.546134Z","iopub.status.idle":"2024-05-19T05:01:11.552650Z","shell.execute_reply.started":"2024-05-19T05:01:11.546105Z","shell.execute_reply":"2024-05-19T05:01:11.551910Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"base_model= AutoModelForCausalLM.from_pretrained(base_model_id,quantization_config=bnb_config,device_map=\"auto\")\nbase_model.config.use_cache=False","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:01:11.553669Z","iopub.execute_input":"2024-05-19T05:01:11.553919Z","iopub.status.idle":"2024-05-19T05:02:33.732998Z","shell.execute_reply.started":"2024-05-19T05:01:11.553898Z","shell.execute_reply":"2024-05-19T05:02:33.732159Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beb05578eb6942668609d6de446498af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"354572a2d32f4c3395c19fcf8872e5d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a037a81521349598d5cce786737ae44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a2e449ca0b4621ada3ef0c1c4f70c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/3.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaeddf6e95db45898aa6d8f61924cb55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367492cf7b36476780011e8c9055c989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/2.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f1f073f85f48bda9766a2d3ae6a3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0220205003f746c99728a5fd3876338b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34abc3d603a4a919b4ceadd53baaf86"}},"metadata":{}}]},{"cell_type":"code","source":"quatnized_model= prepare_model_for_kbit_training(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:02:33.734225Z","iopub.execute_input":"2024-05-19T05:02:33.734568Z","iopub.status.idle":"2024-05-19T05:02:33.764115Z","shell.execute_reply.started":"2024-05-19T05:02:33.734532Z","shell.execute_reply":"2024-05-19T05:02:33.763412Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"peft_model= get_peft_model(model=quatnized_model,peft_config=peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:04:45.206090Z","iopub.execute_input":"2024-05-19T05:04:45.206486Z","iopub.status.idle":"2024-05-19T05:04:45.396367Z","shell.execute_reply.started":"2024-05-19T05:04:45.206453Z","shell.execute_reply":"2024-05-19T05:04:45.395287Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"merged_model = peft_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:02:37.788747Z","iopub.execute_input":"2024-05-19T05:02:37.789044Z","iopub.status.idle":"2024-05-19T05:02:40.694006Z","shell.execute_reply.started":"2024-05-19T05:02:37.789019Z","shell.execute_reply":"2024-05-19T05:02:40.692678Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:02:40.696153Z","iopub.execute_input":"2024-05-19T05:02:40.696536Z","iopub.status.idle":"2024-05-19T05:02:40.703590Z","shell.execute_reply.started":"2024-05-19T05:02:40.696499Z","shell.execute_reply":"2024-05-19T05:02:40.702577Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:02:41.830950Z","iopub.execute_input":"2024-05-19T05:02:41.831287Z","iopub.status.idle":"2024-05-19T05:02:41.856708Z","shell.execute_reply.started":"2024-05-19T05:02:41.831262Z","shell.execute_reply":"2024-05-19T05:02:41.855845Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821d0bf3cba8455e98cb75234b876131"}},"metadata":{}}]},{"cell_type":"code","source":"training_args= TrainingArguments(\n    output_dir='/kaggle/working/Mistral-7B-Fine_Tunned',\n    hub_model_id='Shorya22/Mistral-7B-Fine_Tunned',\n    learning_rate=2e-4,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    evaluation_strategy='epoch',\n    logging_steps=10,\n    save_strategy='epoch',\n    save_steps=10)\n\ntrainer= Trainer(\n    model= peft_model,\n    args=training_args,\n    train_dataset=dataset,\n    eval_dataset=dataset,\n    data_collator=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:06:21.310678Z","iopub.execute_input":"2024-05-19T05:06:21.311056Z","iopub.status.idle":"2024-05-19T05:06:21.939475Z","shell.execute_reply.started":"2024-05-19T05:06:21.311018Z","shell.execute_reply":"2024-05-19T05:06:21.938737Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:06:26.670341Z","iopub.execute_input":"2024-05-19T05:06:26.671176Z","iopub.status.idle":"2024-05-19T06:12:04.671398Z","shell.execute_reply.started":"2024-05-19T05:06:26.671144Z","shell.execute_reply":"2024-05-19T06:12:04.670412Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_050640-b1bpwidv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shorya22/huggingface/runs/b1bpwidv' target=\"_blank\">/kaggle/working/Mistral-7B-Fine_Tunned</a></strong> to <a href='https://wandb.ai/shorya22/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shorya22/huggingface' target=\"_blank\">https://wandb.ai/shorya22/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shorya22/huggingface/runs/b1bpwidv' target=\"_blank\">https://wandb.ai/shorya22/huggingface/runs/b1bpwidv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 1:04:41, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.381700</td>\n      <td>1.313442</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=125, training_loss=1.5632500839233399, metrics={'train_runtime': 3937.5112, 'train_samples_per_second': 0.254, 'train_steps_per_second': 0.032, 'total_flos': 2.185884598272e+16, 'train_loss': 1.5632500839233399, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"new_model= \"Mistral-7B-Fine_Tunned1\"","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:12:29.701639Z","iopub.execute_input":"2024-05-19T06:12:29.702348Z","iopub.status.idle":"2024-05-19T06:12:29.708592Z","shell.execute_reply.started":"2024-05-19T06:12:29.702316Z","shell.execute_reply":"2024-05-19T06:12:29.707494Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:12:32.341695Z","iopub.execute_input":"2024-05-19T06:12:32.342063Z","iopub.status.idle":"2024-05-19T06:12:32.888492Z","shell.execute_reply.started":"2024-05-19T06:12:32.342034Z","shell.execute_reply":"2024-05-19T06:12:32.887296Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"new_model= '/kaggle/working/Mistral-7B-Fine_Tunned1'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:12:38.141451Z","iopub.execute_input":"2024-05-19T06:12:38.141844Z","iopub.status.idle":"2024-05-19T06:12:38.147512Z","shell.execute_reply.started":"2024-05-19T06:12:38.141814Z","shell.execute_reply":"2024-05-19T06:12:38.146567Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\n# Define the base model ID or path\nbase_model = 'NousResearch/Hermes-2-Pro-Mistral-7B'  # replace with actual path or model ID\n\n# Load the base model with appropriate parameters\nmodel = AutoModelForCausalLM.from_pretrained(base_model,\n                                             low_cpu_mem_usage=True,\n                                             return_dict=True,\n                                             torch_dtype=torch.bfloat16,\n                                             device_map=\"auto\")\n\n# Define the path or model ID for the QLoRA adapters\nlora_adapters = '/kaggle/working/Mistral-7B-Fine_Tunned1'  # replace with actual path or model ID\n\n# Load the QLoRA adapters into the model\nmodel = PeftModel.from_pretrained(model, lora_adapters)\n\n# Merge the QLoRA adapters into the base model and unload adapters\nmodel = model.merge_and_unload()\n\n# Load the tokenizer for the base model\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side='right'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:13:58.741895Z","iopub.execute_input":"2024-05-19T06:13:58.742290Z","iopub.status.idle":"2024-05-19T06:14:06.930044Z","shell.execute_reply.started":"2024-05-19T06:13:58.742258Z","shell.execute_reply":"2024-05-19T06:14:06.928829Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5058ce9f02944a029f2452542d94ebb6"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.push_to_hub(\"Mistral-7B-Fine_Tunned_Model\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:14:34.561684Z","iopub.execute_input":"2024-05-19T06:14:34.562444Z","iopub.status.idle":"2024-05-19T06:20:56.698410Z","shell.execute_reply.started":"2024-05-19T06:14:34.562392Z","shell.execute_reply":"2024-05-19T06:20:56.697184Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dff539e3b094178889347a1f27fbd3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8832af98a842e0ae0a25b600171d7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cbfee22060a4dd4948e9b14934f166d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16144319bc64476b90020ea4605c2ba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78af70bf45a049fdba4ff6356d46d8d6"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Shorya22/Mistral-7B-Fine_Tunned_Model/commit/8f93a8f01e08022b500725aaef7687b52a2d0065', commit_message='Upload MistralForCausalLM', commit_description='', oid='8f93a8f01e08022b500725aaef7687b52a2d0065', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.push_to_hub(\"Mistral-7B-Fine_Tunned_Model\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:14:21.241980Z","iopub.execute_input":"2024-05-19T06:14:21.242371Z","iopub.status.idle":"2024-05-19T06:14:25.979315Z","shell.execute_reply.started":"2024-05-19T06:14:21.242338Z","shell.execute_reply":"2024-05-19T06:14:25.978156Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7222da995c3d4b1b8b3180660bcf8c52"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Shorya22/Mistral-7B-Fine_Tunned_Model/commit/d40be50fa941510c2ce9743560f37f95804ce9b3', commit_message='Upload tokenizer', commit_description='', oid='d40be50fa941510c2ce9743560f37f95804ce9b3', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"ll= '''You have a database with two tables: employees and departments. The employees table contains information about each employee, and the departments table contains information about each department.Write an SQL query to retrieve the names of all employees along with the name of the department they belong to.'''","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:25:36.742452Z","iopub.execute_input":"2024-05-19T06:25:36.743200Z","iopub.status.idle":"2024-05-19T06:25:36.749307Z","shell.execute_reply.started":"2024-05-19T06:25:36.743167Z","shell.execute_reply":"2024-05-19T06:25:36.748201Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"start_prompt= \"Write SQL query according to given question or instruction.\\n\\n\"\nend_prompt= \"\\n\\nResponse:\"\nprompt= start_prompt+ll+end_prompt\n\npipe= pipeline(task='text-generation',model=model,tokenizer=tokenizer,max_length=200)\nresult= pipe(prompt)\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-19T06:25:51.882868Z","iopub.execute_input":"2024-05-19T06:25:51.883628Z","iopub.status.idle":"2024-05-19T06:28:58.112637Z","shell.execute_reply.started":"2024-05-19T06:25:51.883596Z","shell.execute_reply":"2024-05-19T06:28:58.111407Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"Write SQL query according to given question or instruction.\n\nYou have a database with two tables: employees and departments. The employees table contains information about each employee, and the departments table contains information about each department.Write an SQL query to retrieve the names of all employees along with the name of the department they belong to.\n\nResponse:\n\nSELECT employees.name, departments.name\nFROM employees, departments\nWHERE employees.department_id = departments.department_id;\n\nExplanation:\nThe query is asking to retrieve the names of all employees along with the name of the department they belong to. To achieve this, we use a SELECT statement to select the employees' name and department's name, followed by a SQL query with a WHERE clause to join the two tables (employees and departments) using the common 'department_id' column. This query returns the desired information.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}